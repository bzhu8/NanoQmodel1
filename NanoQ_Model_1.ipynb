{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bzhu8/NanoQmodel1/blob/main/NanoQ_Model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**NanoQ-model 1.0: An end-to-end trained protein language model predicts the quenching efficiency of quenchbody biosensors**\n",
        "\n",
        "Update: Jan. 25th, 2025\n",
        "\n",
        "Usage guide:\n",
        "1. Run the Step 1 and Step 2 cells to prepare the necessary environment and the model files.\n",
        "2. Input the CDR1 and CDR3 sequence with a space between each amino acid, and a [SEP] between CDR1 and CDR3. The sequence including the three amino acid frameworks should be used to repeat the prediction results in the manuscript.\n",
        "\n",
        " Example sequence: A S G T I F Q V G S V G W [SEP] Y C A A L G Q V S E Y N S A S Y E W T Y P Y W G\n",
        "\n",
        " Format example: A S G (CDR1 seuqnece) M G W [SEP] Y C A (CDR3 seuqnece) Y W G\n",
        "3. Run the Step 3 cell to predict the probability score for quenching. The three amino acid framework sequences can be adjusted according to the antibody sequence of interest.\n",
        "\n",
        "(This model can be used under CC BY-NC-ND 4.0 Deed License)\n",
        "\n",
        "**Reference**: **Akihito Inoue**#, **Bo Zhu**#, Keisuke Mizutani, Ken Kobayashi, Takanobu Yasuda, Alon Wellner, Chang C. Liu, Tetsuya Kitaguchi, Prediction of single-mutation effects for fluorescent immunosensor engineering with an end-to-end trained protein language model, 2024, Jxiv, 971. (#Equal contributions) DOI: https://doi.org/10.51094/jxiv.971"
      ],
      "metadata": {
        "id": "VsJ7oOiz4_SF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@title Step 1: Install Transformers (Please click 'runtime restart' button if appears) < 1 min\n",
        "#Change to transformers version 4.28.1\n",
        "%%capture\n",
        "!pip install transformers==4.28.1\n",
        "\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "kM7IJNDZdDlx",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@title Step 2: Environment preparation + NanoQ-model 1.0 loading ~ 1-2 min.\n",
        "%%capture\n",
        "#import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#import torch.optim as optim\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "#Download NanoQ-model-1.0\n",
        "!wget https://huggingface.co/bzhu8/Qmodel1/resolve/main/230527Qmodel1.pth\n",
        "\n",
        "# BERT tokenizer initiate pLM prot_bert_bfd\n",
        "model_name = \"Rostlab/prot_bert_bfd\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# ProtBERT Transformer model Initialization\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"Rostlab/prot_bert_bfd\").to(device)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(1024, out_features=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        x = self.linear(pooled_output).squeeze()\n",
        "        return x\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Define model\n",
        "model = Transformer().to(device)\n",
        "# Load end-to-end trained NanoQ-model1.0\n",
        "model_path = '/content/230527Qmodel1.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.cpu()\n",
        "max_len = 512"
      ],
      "metadata": {
        "id": "3SMVwdyJWsnz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcCFmq9tVpT_",
        "outputId": "39062f9a-2c0d-4a79-c498-d17d6c331610",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability Score for quenching = 0.672328\n",
            "CPU times: user 933 ms, sys: 4.21 ms, total: 937 ms\n",
            "Wall time: 964 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Step 3: Input the CDR1 and CDR3 sequences to predict the quenching efficiency (probability score, range 0-1)\n",
        "\n",
        "CDR = \"A S G T I F Q V G S V G W [SEP] Y C A A L G Q V S E Y N S A S Y E W T Y P Y W G\" #@param {type:\"string\"}\n",
        "\n",
        "sequences = CDR\n",
        "labels = [0.]\n",
        "\n",
        "#create data\n",
        "pred_seq=pd.DataFrame({\"sequence\":sequences, \"label\":labels})\n",
        "pred_seq\n",
        "encodings = tokenizer(list(pred_seq[\"sequence\"]), truncation=True, padding=True, max_length=max_len, return_tensors='pt')\n",
        "\n",
        "# prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_inputs = {\n",
        "        'input_ids': encodings['input_ids'],\n",
        "        'attention_mask': encodings['attention_mask'],\n",
        "    }\n",
        "    outputs = model(**test_inputs)\n",
        "predictions = F.sigmoid(outputs).cpu().detach().numpy()\n",
        "\n",
        "# print score (probability score)\n",
        "\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print('Probability Score for quenching =', predictions)"
      ]
    }
  ]
}
